import os
import time
import asyncio
import logging
import re
from glob import glob
from dotenv import load_dotenv
from telegram.ext import ContextTypes,Application

from telegram.constants import ParseMode
from telegram.error import TelegramError
import json
from logging.handlers import RotatingFileHandler

# --- ÙØ§Ø² Û±: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø¨Ø§ ÙØ±Ù…Øª JSON ---

class JsonFormatter(logging.Formatter):
    """
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø³ÙØ§Ø±Ø´ÛŒØŒ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ø³Ø§Ø®ØªØ§Ø±ÛŒØ§ÙØªÙ‡ JSON ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    def format(self, record):
        # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù„Ø§Ú¯
        log_record = {
            "timestamp": self.formatTime(record, self.datefmt),
            "level": record.levelname,
            "message": record.getMessage(),
        }
        
        # Ø§ÙØ²ÙˆØ¯Ù† ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ùˆ ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù„Ø§Ú¯ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯
        extra_keys = ['task_name', 'entity_id', 'status', 'details', 'error']
        for key in extra_keys:
            if hasattr(record, key):
                log_record[key] = getattr(record, key)
                
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ù‡ Ø±Ø´ØªÙ‡ JSON
        return json.dumps(log_record, ensure_ascii=False)

# --- Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø§ØµÙ„ÛŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG) # Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±ÛŒÙ† Ø³Ø·Ø­ Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª ØªÙ…Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª

# Û±. Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„ (Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¢Ù†ÛŒ) - Ø¨Ø§ ÙØ±Ù…Øª Ø³Ø§Ø¯Ù‡ Ùˆ Ø®ÙˆØ§Ù†Ø§
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO) # ÙÙ‚Ø· Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ù‡ Ø¨Ø§Ù„Ø§
console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))

# Û². Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ (Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ) - Ø¨Ø§ ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ JSON
# ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù¾Ø³ Ø§Ø² Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø­Ø¬Ù… Ûµ Ù…Ú¯Ø§Ø¨Ø§ÛŒØªØŒ Ø¢Ø±Ø´ÛŒÙˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
file_handler = RotatingFileHandler('watcher.log', maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setLevel(logging.DEBUG) # ØªÙ…Ø§Ù… Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ø± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
file_handler.setFormatter(JsonFormatter()) # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ±Ù…ØªØ± Ø¬Ø¯ÛŒØ¯

# Ø­Ø°Ù Ù…Ø¯ÛŒØ±ÛŒØªâ€ŒÚ©Ù†Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù„Ø§Ú¯ ØªÚ©Ø±Ø§Ø±ÛŒ
if logger.hasHandlers():
    logger.handlers.clear()

# Ø§ÙØ²ÙˆØ¯Ù† Ù…Ø¯ÛŒØ±ÛŒØªâ€ŒÚ©Ù†Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ Ù„Ø§Ú¯Ø±
logger.addHandler(console_handler)
logger.addHandler(file_handler)

# Ú©Ø§Ù‡Ø´ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
logging.getLogger('httpx').setLevel(logging.WARNING)

# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ ---



# --- Load Environment Variables ---
load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
ADMIN_ID = os.getenv("ADMIN_ID")
LOG_DIRECTORY_PATH = os.getenv("LOG_DIRECTORY_PATH")
CHANNEL_ID = os.getenv("CHANNEL_ID")
ECOSYSTEM_PATH = os.getenv("ECOSYSTEM_PATH")





# --- ÙØ§Ø² Û±ØŒ Ø¨Ø®Ø´ Ø¯ÙˆÙ…: Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¶Ø¹ÛŒØª Ø§ØªÙ…ÛŒÚ© Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡ ---

# State file path for stateless operation
WATCHER_STATE_PATH = os.path.join(os.path.dirname(ECOSYSTEM_PATH) if ECOSYSTEM_PATH else '.', 'watcher_state.json') if ECOSYSTEM_PATH else 'watcher_state.json'

source_name_map = {}
state_data = {}  # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³Ø±Ø§Ø³Ø±ÛŒ
state_changed = False  # ÙÙ„Ú¯ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ

def load_source_names():
    """
    Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ ecosystem.json Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    """
    global source_name_map
    if not ECOSYSTEM_PATH:
        logger.warning("ECOSYSTEM_PATH not set. Skipping source names load.", extra={'status': 'skipped'})
        return
    try:
        with open(ECOSYSTEM_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # ÙÙ‚Ø· Ù…Ù†Ø§Ø¨Ø¹ÛŒ Ú©Ù‡ file_path Ùˆ name Ø¯Ø§Ø±Ù†Ø¯ Ø±Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        temp_map = {
            source['file_path']: source['name'] 
            for source in data.get('sources', []) 
            if 'file_path' in source and 'name' in source
        }
        # ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ØŒ Ù…ØªØºÛŒØ± Ø³Ø±Ø§Ø³Ø±ÛŒ Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ù†
        source_name_map = temp_map
        logger.info(f"Loaded {len(source_name_map)} source names from ecosystem.json.", extra={'status': 'success'})
    except FileNotFoundError:
        logger.warning(f"ecosystem.json not found at {ECOSYSTEM_PATH}. Using empty source map.", extra={'entity_id': ECOSYSTEM_PATH})
    except json.JSONDecodeError as e:
        logger.error("JSON decode error in ecosystem.json.", extra={'error': str(e), 'status': 'failure'})
    except Exception as e:
        logger.error("Failed to load or parse ecosystem.json.", extra={'error': str(e), 'status': 'failure'})

def load_watcher_state():
    """
    ÙˆØ¶Ø¹ÛŒØª watcher Ø±Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON Ø¨Ø§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø®Ø·Ø§ØŒ Ø¨Ø§ ÛŒÚ© ÙˆØ¶Ø¹ÛŒØª Ø®Ø§Ù„ÛŒ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not os.path.exists(WATCHER_STATE_PATH):
        logger.info(f"State file not found, starting fresh.", extra={'entity_id': WATCHER_STATE_PATH})
        return {}
    try:
        with open(WATCHER_STATE_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: Ø¢ÛŒØ§ Ø¯Ø§Ø¯Ù‡ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³Øª Ùˆ Ø¢ÛŒØ§ Ú©Ù„ÛŒØ¯Ù‡Ø§ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¢Ù† Ø±Ø´ØªÙ‡ Ù‡Ø³ØªÙ†Ø¯ØŸ
        if not isinstance(data, dict) or not all(isinstance(k, str) and isinstance(v, str) for k, v in data.items()):
            raise ValueError("Invalid state format: must be a dictionary of strings.")
        logger.info(f"Loaded state with {len(data)} entries.", extra={'entity_id': WATCHER_STATE_PATH, 'status': 'success'})
        return data
    except (json.JSONDecodeError, ValueError) as e:
        logger.error("Corrupt or invalid state file. Starting with empty state.", extra={'entity_id': WATCHER_STATE_PATH, 'error': str(e), 'status': 'failure'})
        return {}
    except Exception as e:
        logger.error("Failed to load state file.", extra={'entity_id': WATCHER_STATE_PATH, 'error': str(e), 'status': 'failure'})
        return {}

def save_watcher_state(state: dict):
    """
    ÙˆØ¶Ø¹ÛŒØª watcher Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø§ØªÙ…ÛŒÚ© Ø¯Ø± ÙØ§ÛŒÙ„ JSON Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³Ø¯ Ùˆ Ø³Ù¾Ø³ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    tmp_path = WATCHER_STATE_PATH + '.tmp'
    try:
        with open(tmp_path, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        # Ø¹Ù…Ù„ÛŒØ§Øª Ø§ØªÙ…ÛŒÚ©: Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ø¨Ø§ ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
        os.replace(tmp_path, WATCHER_STATE_PATH)
        logger.debug(f"Saved state with {len(state)} entries.", extra={'status': 'success'})
    except Exception as e:
        logger.error("Failed to save state file.", extra={'error': str(e), 'status': 'failure'})
        # Ø§Ú¯Ø± Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯ØŒ ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ø±Ø§ Ø­Ø°Ù Ú©Ù† ØªØ§ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯
        if os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception as remove_e:
                logger.error(f"Failed to remove temporary state file.", extra={'error': str(remove_e)})

# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¶Ø¹ÛŒØª ---



# --- ÙØ§Ø² Û²ØŒ Ø¨Ø®Ø´ Ø¯ÙˆÙ…: Ø§Ø±Ø³Ø§Ù„ Ø§Ø¹Ù„Ø§Ù† Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… ---

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
last_message_hash = None
last_message_time = 0
DEDUPLICATION_COOLDOWN = 10  # (Ø«Ø§Ù†ÛŒÙ‡) - Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

async def send_telegram_alert(context: ContextTypes.DEFAULT_TYPE, message: str):
    """
    Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    - Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    - Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡ØŒ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    global last_message_hash, last_message_time
    
    target_id = CHANNEL_ID if CHANNEL_ID else ADMIN_ID
    if not target_id:
        logger.warning("No target ID (CHANNEL_ID or ADMIN_ID) is set. Skipping alert.", extra={'status': 'skipped'})
        return

    # --- Ù…Ù†Ø·Ù‚ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³Ù¾Ù… ---
    current_time = time.time()
    message_hash = hash(message)
    if message_hash == last_message_hash and (current_time - last_message_time) < DEDUPLICATION_COOLDOWN:
        logger.info("Skipping duplicate alert.", extra={'details': message[:50] + '...'})
        return
    
    # --- Ù…Ù†Ø·Ù‚ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ø¹Ù‚Ø¨â€ŒÙ†Ø´ÛŒÙ†ÛŒ Ù†Ù…Ø§ÛŒÛŒ (Exponential Backoff) ---
    max_retries = 3
    delay = 1.0  # Ø´Ø±ÙˆØ¹ Ø¨Ø§ Û± Ø«Ø§Ù†ÛŒÙ‡ ØªØ§Ø®ÛŒØ±

    for attempt in range(max_retries + 1):
        try:
            await context.bot.send_message(chat_id=target_id, text=message, parse_mode=ParseMode.MARKDOWN)
            
            # Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØªØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾ÛŒØ§Ù… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
            last_message_hash = message_hash
            last_message_time = current_time
            
            logger.info("Alert sent successfully.", extra={'target_id': target_id, 'status': 'success'})
            return # Ø§Ø² Ø­Ù„Ù‚Ù‡ Ø®Ø§Ø±Ø¬ Ø´Ùˆ

        except TelegramError as e:
            log_extra = {'error': str(e), 'attempt': f"{attempt + 1}/{max_retries + 1}", 'status': 'retry_failed'}
            if attempt < max_retries:
                logger.warning(f"Failed to send alert, retrying in {delay:.1f}s...", extra=log_extra)
                await asyncio.sleep(delay)
                delay *= 2  # Ø²Ù…Ø§Ù† ØªØ§Ø®ÛŒØ± Ø±Ø§ Ø¯Ùˆ Ø¨Ø±Ø§Ø¨Ø± Ú©Ù†
            else:
                logger.error("Failed to send alert after multiple retries.", extra=log_extra)
                # Ø§Ú¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ ÛŒÚ© Ø¨Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹ Ø¨Ø¯Ù‡
                if target_id == CHANNEL_ID and ADMIN_ID:
                    try:
                        fallback_msg = f"âš ï¸ *Channel Send Failed*\n\nOriginal message:\n{message}"
                        await context.bot.send_message(chat_id=ADMIN_ID, text=fallback_msg, parse_mode=ParseMode.MARKDOWN)
                        logger.info("Fallback alert sent to ADMIN_ID.", extra={'status': 'fallback_success'})
                    except TelegramError as e2:
                        logger.critical("Fallback to ADMIN_ID also failed.", extra={'error': str(e2), 'status': 'fallback_failed'})
                return # Ø´Ú©Ø³Øª Ù†Ù‡Ø§ÛŒÛŒ
        except Exception as e:
            logger.critical("An unexpected error occurred in send_telegram_alert.", extra={'error': str(e)})
            return
            
# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ø§Ø±Ø³Ø§Ù„ Ø§Ø¹Ù„Ø§Ù† ---



# --- ÙØ§Ø² Û²ØŒ Ø¨Ø®Ø´ Ø§ÙˆÙ„: ØªØ¬Ø²ÛŒÙ‡ Ù„Ø§Ú¯ Ø¨Ø§ Regex (Robust Parsing) ---

# Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Regex Ø§Ø² Ù¾ÛŒØ´ Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ù‡ØªØ±
# Ø§ÛŒÙ† Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Parse Error Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ù…ÛŒØ´Ù‡ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.
open_pattern = re.compile(r'\[TRADE_OPEN\]\s+(.*)')
close_pattern = re.compile(r'\[TRADE_CLOSE\]\s+(.*)')
alert_pattern = re.compile(r'\[DD_ALERT\]\s+(.*)')
stop_pattern = re.compile(r'\[DD_STOP\]\s+(.*)')
error_pattern = re.compile(r'\[ERROR\]\s+-\s+(.*)')

def parse_and_format_log_line(line: str, state: dict) -> str | None:
    """
    ÛŒÚ© Ø®Ø· Ù„Ø§Ú¯ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Regex ØªØ¬Ø²ÛŒÙ‡ Ùˆ Ø¨Ù‡ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø®ÙˆØ§Ù†Ø§ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ù…Ù‚Ø§ÙˆÙ… Ø§Ø³Øª Ùˆ Ø®Ø·Ø§Ù‡Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    global state_changed

    line = line.strip()
    if not line:
        return None

    try:
        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§Ú¯ TRADE_OPEN ---
        if match := open_pattern.search(line):
            # Ù…Ø«Ø§Ù„: copy_A,XAUUSD,0.11 (Source:0.11,Mult:1.00),4245.71000,178661555,TradeCopier_S2.txt
            parts_str = match.group(1)
            # Ø§Ø² Regex Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø§Ù…Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            parts = re.match(r'([^,]+),\s*([^,]+),\s*([^,]+),\s*([^,]+),\s*([^,]+),\s*([^,]+)', parts_str)
            if not parts or len(parts.groups()) != 6:
                raise ValueError(f"Invalid OPEN format: {parts_str}")
            
            copy_id, symbol, volume_info, price, source_ticket, source_file = [p.strip() for p in parts.groups()]
            source_name = source_name_map.get(source_file, source_file)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù„Ø§Ú¯ TRADE_CLOSE
            if state.get(source_ticket) != source_name:
                state[source_ticket] = source_name
                state_changed = True
                
            return (
                f"âœ… *New Position Opened*\n\n"
                f"*Source:* `{source_name}`\n"
                f"*Copy Account:* `{copy_id}`\n"
                f"*Symbol:* `{symbol}`\n"
                f"*Volume:* `{volume_info}`\n"
                f"*Open Price:* `{price}`\n"
                f"*Source Ticket:* `{source_ticket}`"
            )

        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§Ú¯ TRADE_CLOSE ---
        elif match := close_pattern.search(line):
            parts = match.group(1).split(',')
            # ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù†Ø§Ù… ÙØ§ÛŒÙ„: copy_A,XAUUSD,178662307,-5.06,TradeCopier_S2.txt
            if len(parts) == 5:
                copy_id, symbol, source_ticket, profit_str, source_file = [p.strip() for p in parts]
                source_name = source_name_map.get(source_file, source_file)
            # ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ: copy_A,XAUUSD,178662307,-5.06
            elif len(parts) == 4:
                copy_id, symbol, source_ticket, profit_str = [p.strip() for p in parts]
                # Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹ Ø±Ø§ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒÙ…
                source_name = state.get(source_ticket, 'Unknown Source')
            else:
                raise ValueError(f"Invalid CLOSE format: expected 4 or 5 parts, got {len(parts)}")
            
            profit = float(profit_str)
            profit_text = f"+${profit:,.2f}" if profit >= 0 else f"-${abs(profit):,.2f}"
            emoji = "â˜‘ï¸" if profit >= 0 else "ğŸ”»"
            
            # Ù¾Ø³ Ø§Ø² Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù†ØŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø±Ø§ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            if source_ticket in state:
                del state[source_ticket]
                state_changed = True
                
            return (
                f"{emoji} *Position Closed*\n\n"
                f"*Source:* `{source_name}`\n"
                f"*Copy Account:* `{copy_id}`\n"
                f"*Symbol:* `{symbol}`\n"
                f"*Profit/Loss:* `{profit_text}`\n"
                f"*Source Ticket:* `{source_ticket}`"
            )

        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§Ú¯ DD_ALERT ---
        elif match := alert_pattern.search(line):
            parts = [p.strip() for p in match.group(1).split(',')]
            if len(parts) != 5:
                raise ValueError(f"Invalid ALERT format: expected 5 parts, got {len(parts)}")
            copy_id, dd, dollar_loss, start_equity, peak_equity = parts
            return (
                f"ğŸŸ¡ *Daily Drawdown Alert*\n\n"
                f"*Account:* `{copy_id}`\n"
                f"*Current Loss:* `%{float(dd):.2f}` `(-${float(dollar_loss):,.2f})`\n"
                f"*Daily Start Equity:* `${float(start_equity):,.2f}`\n"
                f"*Daily Peak Equity:* `${float(peak_equity):,.2f}`"
            )

        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§Ú¯ DD_STOP ---
        elif match := stop_pattern.search(line):
            parts = [p.strip() for p in match.group(1).split(',')]
            if len(parts) != 6:
                raise ValueError(f"Invalid STOP format: expected 6 parts, got {len(parts)}")
            copy_id, dd, dd_limit, dollar_loss, start_equity, peak_equity = parts
            return (
                f"ğŸ”´ *Copy Stopped Due to DD Limit*\n\n"
                f"*Account:* `{copy_id}`\n"
                f"*Loss at Stop:* `%{float(dd):.2f}` `(-${float(dollar_loss):,.2f})`\n"
                f"*Stop Threshold:* `%{float(dd_limit):,.2f}`"
            )

        # --- Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„Ø§Ú¯ ERROR ---
        elif match := error_pattern.search(line):
            error_message = match.group(1).strip()
            # Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¹Ø¯Ù… ÛŒØ§ÙØªÙ† ÙØ§ÛŒÙ„ Ø³ÙˆØ±Ø³ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ… ØªØ§ Ø§Ø³Ù¾Ù… Ù†Ø´ÙˆØ¯
            if "Failed to open source file" in error_message:
                logger.debug("Ignoring non-critical source file error.", extra={'details': error_message})
                return None
            return f"ğŸš¨ *Expert Error*\n\n`{error_message}`"

    except (ValueError, IndexError) as e:
        # Ø§Ú¯Ø± Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ¬Ø²ÛŒÙ‡ Ø±Ø® Ø¯Ø§Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù‡Ø´Ø¯Ø§Ø± Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù‡ Ùˆ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        logger.warning(f"Malformed log line skipped: '{line}'. Error: {e}", extra={'status': 'parse_error'})
        return f"âš ï¸ *Parse Error in Log*\n`{line}`"

    return None

# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ ØªØ¬Ø²ÛŒÙ‡ Ù„Ø§Ú¯ ---




# --- ÙØ§Ø² Û³ØŒ Ø¨Ø®Ø´ Ø§ÙˆÙ„: Ù†Ø¸Ø§Ø±Øª Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù† Ø¨Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---

async def follow_log_file(context: ContextTypes.DEFAULT_TYPE, filepath: str, state: dict):
    """
    ÛŒÚ© ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù† Ø¯Ù†Ø¨Ø§Ù„ Ú©Ø±Ø¯Ù‡ Ùˆ Ø®Ø·ÙˆØ· Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ØªØ± Ø®Ø·Ø§Ù‡Ø§ Ùˆ Ù„ØºÙˆ Ø´Ø¯Ù† ØªØ³Ú© Ø¨Ù‡ÛŒÙ†Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.
    """
    task_name = asyncio.current_task().get_name()
    log_extra = {'task_name': task_name, 'entity_id': os.path.basename(filepath)}
    
    logger.info("Starting to watch log file.", extra=log_extra)
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # Ø±ÙØªÙ† Ø¨Ù‡ Ø§Ù†ØªÙ‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù† Ø®Ø·ÙˆØ· Ø¬Ø¯ÛŒØ¯
            f.seek(0, 2)
            while True:
                line = f.readline()
                if not line:
                    await asyncio.sleep(1) # Ø§Ú¯Ø± Ø®Ø· Ø¬Ø¯ÛŒØ¯ÛŒ Ù†Ø¨ÙˆØ¯ØŒ ÛŒÚ© Ø«Ø§Ù†ÛŒÙ‡ ØµØ¨Ø± Ú©Ù†
                    continue
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø®Ø· Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù… ÙØ±Ù…Øª Ø´Ø¯Ù‡
                formatted_message = parse_and_format_log_line(line, state)
                
                if formatted_message:
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø§Ø±Ø³Ø§Ù„ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¬Ø¯ÛŒØ¯
                    await send_telegram_alert(context, formatted_message)

    except FileNotFoundError:
        logger.warning("Log file was not found or has been deleted. Task is stopping.", extra=log_extra)
    except asyncio.CancelledError:
        logger.info("Log file watch task has been cancelled (likely due to a new log file).", extra=log_extra)
        # Ø§ÛŒÙ† Ø®Ø·Ø§ Ø·Ø¨ÛŒØ¹ÛŒ Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… Ø®Ø§ØµÛŒ Ù†Ø¯Ø§Ø±Ø¯
        pass
    except Exception as e:
        logger.error("An unexpected error occurred while watching log file.", extra={**log_extra, 'error': str(e), 'status': 'failure'})
        # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡ØŒ Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹ Ø¨Ø¯Ù‡
        await send_telegram_alert(context, f"ğŸš¨ *Critical Watcher Error*\n\nTask `{task_name}` failed while watching `{os.path.basename(filepath)}`\nError: `{str(e)}`")

# --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ ---#






# --- ÙØ§Ø² Û³ØŒ Ø¨Ø®Ø´ Ø¯ÙˆÙ…: Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª ---

async def batch_state_saver(state: dict):
    """
    Ø§ÛŒÙ† ØªØ³Ú© Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ùˆ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ØŒ ÙˆØ¶Ø¹ÛŒØª Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    global state_changed
    while True:
        await asyncio.sleep(10) # Ù‡Ø± Û±Û° Ø«Ø§Ù†ÛŒÙ‡ ÛŒÚ© Ø¨Ø§Ø± Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        if state_changed:
            save_watcher_state(state)
            state_changed = False # ÙÙ„Ú¯ Ø±Ø§ Ø±ÛŒØ³Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯

async def health_checker():
    """
    Ø§ÛŒÙ† ØªØ³Ú© Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ ÛŒÚ© Ù¾ÛŒØ§Ù… Ø³Ù„Ø§Ù…Øª Ø¯Ø± Ù„Ø§Ú¯ Ø«Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ø²Ù†Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒÙ….
    """
    while True:
        await asyncio.sleep(300) # Ù‡Ø± Ûµ Ø¯Ù‚ÛŒÙ‚Ù‡ ÛŒÚ© Ø¨Ø§Ø±
        logger.info("Watcher health check: Alive and monitoring.", extra={'status': 'healthy'})

async def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ú©Ù‡ ØªÙ…Ø§Ù… ØªØ³Ú©â€ŒÙ‡Ø§ Ø±Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    """
    if not all([BOT_TOKEN, ADMIN_ID, LOG_DIRECTORY_PATH]):
        logger.critical("Missing essential environment variables (BOT_TOKEN, ADMIN_ID, LOG_DIRECTORY_PATH). Exiting.")
        return

    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ApplicationBuilder Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ø±Ù†
    application = Application.builder().token(BOT_TOKEN).build()
    logger.info("Log Watcher v3.3 Professional Edition started.")

    global state_data
    state_data = load_watcher_state()

    # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
    asyncio.create_task(batch_state_saver(state_data), name="StateSaver")
    asyncio.create_task(health_checker(), name="HealthChecker")

    watched_slaves = {} # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„

    while True:
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ø¯Ø¯ Ù†Ø§Ù… Ø³ÙˆØ±Ø³â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØªØºÛŒÛŒØ±Ø§Øª
            load_source_names()

            log_pattern = os.path.join(LOG_DIRECTORY_PATH, "TradeCopier_*.log")
            all_files = glob(log_pattern)

            slaves_logs = {}
            for f in all_files:
                # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø´Ù†Ø§Ø³Ù‡ slave Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„
                match = re.search(r"TradeCopier_(.*?)_\d{4}\.\d{2}\.\d{2}\.log", os.path.basename(f))
                if match:
                    slave_id = match.group(1)
                    # Ø§Ú¯Ø± slave_id Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯ (Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§Ú©Ø³Ù¾Ø±Øª Ø³ÙˆØ±Ø³)ØŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±
                    if slave_id:
                        slaves_logs.setdefault(slave_id, []).append(f)

            for slave_id, files in slaves_logs.items():
                latest_file = max(files, key=os.path.getctime)
                
                # Ø§Ú¯Ø± Ø§ÛŒÙ† slave Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± Ø§Ø³Øª Ú©Ù‡ Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÛŒØ§ ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø¢Ù† ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡
                if slave_id not in watched_slaves or watched_slaves[slave_id]['filepath'] != latest_file:
                    if slave_id in watched_slaves:
                        logger.info(f"Switching log file for '{slave_id}'.", extra={'entity_id': slave_id, 'details': f"From {os.path.basename(watched_slaves[slave_id]['filepath'])} to {os.path.basename(latest_file)}"})
                        # ØªØ³Ú© Ù‚Ø¯ÛŒÙ…ÛŒ Ø±Ø§ Ù„ØºÙˆ Ú©Ù†
                        watched_slaves[slave_id]['task'].cancel()
                    
                    # ØªØ³Ú© Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ø§ÛŒØ¬Ø§Ø¯ Ú©Ù†
                    task = asyncio.create_task(follow_log_file(application, latest_file, state_data))
                    task.set_name(f"watcher_{slave_id}")
                    watched_slaves[slave_id] = {'filepath': latest_file, 'task': task}

            await asyncio.sleep(60) # Ù‡Ø± Û¶Û° Ø«Ø§Ù†ÛŒÙ‡ ÛŒÚ© Ø¨Ø§Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯

        except Exception as e:
            logger.critical("A critical error occurred in the main loop.", extra={'error': str(e), 'status': 'main_loop_failure'})
            await asyncio.sleep(60) # Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ØŒ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Watcher stopped by user (Ctrl+C).")
    except Exception as e:
        logger.critical(f"Fatal error starting the watcher: {e}", exc_info=True)